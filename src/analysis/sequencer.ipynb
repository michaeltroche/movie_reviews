{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Review Sequencer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import icecream as ic\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import time\n",
    "import enchant\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Unnecessary Warnings\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataframe and first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatening dataframes\n",
    "df = pd.DataFrame()\n",
    "for df_file in os.listdir('../../review_dfs'):    \n",
    "    df_new = pd.read_pickle(f'../../review_dfs/{df_file}')\n",
    "    \n",
    "    if df.empty:\n",
    "        df = df_new\n",
    "    else:\n",
    "        df = pd.concat([df, df_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>meter_score</th>\n",
       "      <th>user</th>\n",
       "      <th>post_date</th>\n",
       "      <th>verified</th>\n",
       "      <th>super_reviewer</th>\n",
       "      <th>spoilers</th>\n",
       "      <th>profanity</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9_songs</td>\n",
       "      <td>2004</td>\n",
       "      <td>24</td>\n",
       "      <td>978825829</td>\n",
       "      <td>2020-08-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The only erotic movie in all movies that had a...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9_songs</td>\n",
       "      <td>2004</td>\n",
       "      <td>24</td>\n",
       "      <td>977906655</td>\n",
       "      <td>2019-11-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I like both sex and music and yet this movie h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9_songs</td>\n",
       "      <td>2004</td>\n",
       "      <td>24</td>\n",
       "      <td>978364060</td>\n",
       "      <td>2019-10-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I want to watch it but I don't know how</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9_songs</td>\n",
       "      <td>2004</td>\n",
       "      <td>24</td>\n",
       "      <td>977673194</td>\n",
       "      <td>2018-12-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Margo Stilley is a goddess!</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9_songs</td>\n",
       "      <td>2004</td>\n",
       "      <td>24</td>\n",
       "      <td>977165620</td>\n",
       "      <td>2018-06-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I really liked the movie.  Best dick I have ev...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373788</th>\n",
       "      <td>262</td>\n",
       "      <td>year_of_the_dragon</td>\n",
       "      <td>1985</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-04-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I just rewatched this movie after not having s...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373789</th>\n",
       "      <td>263</td>\n",
       "      <td>year_of_the_dragon</td>\n",
       "      <td>1985</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-03-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Now this is a Mickey Rourke movie! A good chin...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373790</th>\n",
       "      <td>264</td>\n",
       "      <td>year_of_the_dragon</td>\n",
       "      <td>1985</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-02-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>more like year of the spenceman...am i right? ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373791</th>\n",
       "      <td>265</td>\n",
       "      <td>year_of_the_dragon</td>\n",
       "      <td>1985</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-02-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RENT THIS!!!!! UNDERRATED!!!!!!!!!!!!</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373792</th>\n",
       "      <td>266</td>\n",
       "      <td>year_of_the_dragon</td>\n",
       "      <td>1985</td>\n",
       "      <td>56</td>\n",
       "      <td>900817266</td>\n",
       "      <td>2005-11-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[font=Arial Black]GREAT A CULT CLASSIC AND GRE...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373793 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index          movie_name movie_year  meter_score       user  \\\n",
       "0           0             9_songs       2004           24  978825829   \n",
       "1           1             9_songs       2004           24  977906655   \n",
       "2           2             9_songs       2004           24  978364060   \n",
       "3           3             9_songs       2004           24  977673194   \n",
       "4           4             9_songs       2004           24  977165620   \n",
       "...       ...                 ...        ...          ...        ...   \n",
       "373788    262  year_of_the_dragon       1985           56        NaN   \n",
       "373789    263  year_of_the_dragon       1985           56        NaN   \n",
       "373790    264  year_of_the_dragon       1985           56        NaN   \n",
       "373791    265  year_of_the_dragon       1985           56        NaN   \n",
       "373792    266  year_of_the_dragon       1985           56  900817266   \n",
       "\n",
       "        post_date  verified  super_reviewer  spoilers  profanity  \\\n",
       "0       2020-08-2         0               0         0          1   \n",
       "1       2019-11-2         0               0         0          1   \n",
       "2       2019-10-3         0               0         0          0   \n",
       "3       2018-12-2         0               0         0          0   \n",
       "4       2018-06-0         0               0         0          0   \n",
       "...           ...       ...             ...       ...        ...   \n",
       "373788  2006-04-1         0               0         0          0   \n",
       "373789  2006-03-1         0               0         0          0   \n",
       "373790  2006-02-1         0               0         0          0   \n",
       "373791  2006-02-1         0               0         0          0   \n",
       "373792  2005-11-0         0               0         0          0   \n",
       "\n",
       "                                                   review  rating  \n",
       "0       The only erotic movie in all movies that had a...     5.0  \n",
       "1       I like both sex and music and yet this movie h...     1.0  \n",
       "2                 I want to watch it but I don't know how     4.0  \n",
       "3                             Margo Stilley is a goddess!     5.0  \n",
       "4       I really liked the movie.  Best dick I have ev...     5.0  \n",
       "...                                                   ...     ...  \n",
       "373788  I just rewatched this movie after not having s...     2.0  \n",
       "373789  Now this is a Mickey Rourke movie! A good chin...     5.0  \n",
       "373790  more like year of the spenceman...am i right? ...     5.0  \n",
       "373791              RENT THIS!!!!! UNDERRATED!!!!!!!!!!!!     4.0  \n",
       "373792  [font=Arial Black]GREAT A CULT CLASSIC AND GRE...     5.0  \n",
       "\n",
       "[373793 rows x 12 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe head\n",
    "df.reset_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually checking for problem reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_random = df.sample(frac=1)\n",
    "\n",
    "# for i in range(len(df_random)):\n",
    "#     review = df_random.iloc[i]['review']\n",
    "#     print('- ' + review)\n",
    "#     inp = input('\\t')\n",
    "#     if len(inp)>0:\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem code examples\n",
    "\n",
    "- [font=Century Gothic]This movie was an incredibly moving piece. The character arcs are beautiful and horrifying. It will depress you.[/font]\n",
    "\n",
    "- [font=Impact]it was a great movie and i want to see it again!i think mel gibson did a tremendious job![/font]\n",
    "\n",
    "- [center][font=Arial, Helvetica, sans-serif][color=#ff0000][b]\"The entire artistic design of the film is so outlandish that words don't do it justice.\"[/b][/color][/font][/center]\n",
    "[center][b][font=Arial][color=#ff0000][/color][/font][/b] [/center]\n",
    "[center]Read Mike's full review by clicking below:[/center]\n",
    "[url=\"http://www.moviepulse.net/mp_pages/dvd/page_clockworkorange.php\"][img]http://www.moviepulse.net/mp_pages/dvd/screenshots/clockworkorange/clockworkorange.jpg[/img][/url]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering reviews\n",
    "### Removing HTML tagged reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlighting HTML tag reviews\n",
    "df_html = df.loc[df['review'].str.contains('\\[/')]\n",
    "\n",
    "# Removing HTMl tags using .replace and re.sub\n",
    "str_remove   = ['[b]','[/b]',\n",
    "                '[i]','[/i]',\n",
    "                '[u]','[/u]',\n",
    "                '[indent]','[/indent]',\n",
    "                '[center]','[/center]',\n",
    "                '[left]','[/left]',\n",
    "                '[right]','[/right]',\n",
    "                '[spoiler]','[/spoiler]',\n",
    "                '[quote]','[/quote]',\n",
    "                '[list]','[/list]',\n",
    "                '[/size]','[/font]','[/color]']\n",
    "\n",
    "regex_remove = [r'\\[IMG\\].+\\[\\/IMG\\]', # IMG\n",
    "                r'\\[img\\].+\\[\\/img\\]', # img\n",
    "                r'\\[url\\=.+\\[\\/url\\]', # url\n",
    "                r'\\[\\/?size=[0-9]+]',  # size\n",
    "                r'\\[\\/?color=[A-Za-z]+]', # color\n",
    "                r'\\[\\/?font=[A-za-z\\s]+\\]', # font\n",
    "                r'\\[email\\=\\\".+\\[\\/email\\]'] # email\n",
    "\n",
    "review_clean = []\n",
    "for review in df_html['review']:\n",
    "    review = review.lower()\n",
    "    for item in str_remove:\n",
    "        review = review.replace(item, '')\n",
    "        \n",
    "    for regex_pattern in regex_remove:\n",
    "        review = re.sub(pattern = regex_pattern,\n",
    "                        repl    = '',\n",
    "                        string  = review)\n",
    "        \n",
    "    review_clean.append(review)\n",
    "    \n",
    "df['review'].loc[df['review'].str.contains('\\[/')] = review_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing non-english reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-101ccafd8b7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreview_tokenized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mj\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mnon_eng\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnon_eng\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\enchant\\__init__.py\u001b[0m in \u001b[0;36mcheck\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    625\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"can't check spelling of empty string\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m         \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdict_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_this\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\enchant\\_enchant.py\u001b[0m in \u001b[0;36mdict_check\u001b[1;34m(dict, word)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdict_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdict_check1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dictionary of US-english words\n",
    "d = enchant.Dict(\"en_US\")\n",
    "\n",
    "idx = 0\n",
    "remove_idx_noneng = []\n",
    "for review in df['review']:\n",
    "    review = review.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    review_tokenized = tokenizer.tokenize(review)\n",
    "    \n",
    "    # If 10/20 words are non-eng, flag review\n",
    "    j = 0\n",
    "    non_eng = 0\n",
    "    for word in review_tokenized:\n",
    "        j += 1\n",
    "        if d.check(word)==False:\n",
    "            non_eng += 1\n",
    "        if non_eng == 10 or j > 20:\n",
    "            remove_idx_noneng.append(idx)\n",
    "            idx += 1\n",
    "            break\n",
    "            \n",
    "print(remove_idx_noneng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing any reviews that still contain HTML tag variations\n",
    "df_remove  = df.loc[df['review'].str.contains('\\[/')]\n",
    "remove_idx_html = list(df_remove.index)\n",
    "df = df.drop(df.index[remove_idx_html])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and stemming for one review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "processed_review = []\n",
    "for review in df['review']:\n",
    "    review = review.lower()\n",
    "\n",
    "    # Replacing digits with corresponding word\n",
    "    numbers = [1,2,3,4,5,6,7,8,9,0]\n",
    "    num_words = ['one','two','three','four','five','six','seven','eight','nine','zero']\n",
    "    for number, number_word in zip(numbers, num_words):\n",
    "        review = review.replace(f'{number}',f'{number_word}')\n",
    "\n",
    "    # Tokenizing into list - removing all punctuation and separating by word\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    review_tokenized = tokenizer.tokenize(review)\n",
    "\n",
    "    # Stop word filtration\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    review_filtered = [w for w in review_tokenized if w not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    ps = PorterStemmer()\n",
    "    review_stemmed = [ps.stem(i) for i in review_filtered]\n",
    "    \n",
    "    processed_review.append(review_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to sequence process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120, 1, 47, 121, 122, 6, 21, 123, 124, 125, 126, 127, 48, 128, 5, 129, 130, 131, 49, 132, 133, 5, 1], [50, 134, 51, 2, 135, 3, 136, 52, 1], [137, 53, 6, 1, 54, 138, 8, 139], [55, 140, 22, 56, 141, 23, 24, 142, 1, 24, 25, 57, 26, 7, 58, 23, 143, 144, 145, 146, 27, 47, 147, 148, 28, 149, 150, 151, 29, 152, 59, 153, 1], [3, 9, 10, 11, 4, 154, 1, 26, 7, 58, 155, 30, 31, 1, 156, 157, 158, 23, 8, 8, 60, 12, 159, 4, 160, 161, 61, 3, 162, 163, 62, 164, 1, 63, 165, 166, 3, 60, 4, 14, 2, 32, 64, 15, 16, 167, 3, 168, 33, 65, 169, 4, 5, 4, 15, 16, 66, 170, 171, 67, 2, 172, 68, 69, 173, 17, 174, 175, 70, 176, 66, 49, 18, 177, 2, 33, 71, 3, 69, 19, 72, 13, 73, 61, 68, 178, 179, 180, 181, 182, 74, 183, 75, 25, 184, 185, 64, 186, 62, 76, 187, 34, 73, 188, 13, 74, 35, 25, 77, 50, 36, 36, 59, 3, 189, 190, 191, 37, 78, 67, 192, 2, 32, 2, 27, 27, 193, 2, 79, 194, 3, 52, 195, 196, 197, 2, 38, 80, 198, 65, 199, 6, 1, 34, 77, 81, 2, 35, 30, 31], [3, 200, 201, 202, 9, 10, 11, 1, 203, 2, 204, 205, 206, 207, 28, 13, 9, 10, 11, 208, 82, 209, 210, 211, 212, 213, 83, 39, 214, 84, 215, 216, 217, 218, 18, 219, 220, 221, 40, 37, 1, 41, 5, 4, 41, 222, 85, 223, 86, 224, 54], [225, 226, 227, 1, 228, 42, 81, 9, 10, 11, 229, 230, 55, 87, 71, 88, 14, 89, 231, 22, 232, 233, 90, 3, 234, 235, 7, 236, 237, 238, 91, 239, 57, 1, 240, 21, 241, 13, 5, 92, 242, 243, 244, 245, 246, 13, 247, 88, 14, 248, 249, 250, 251, 93, 22, 252, 253, 254, 94, 90, 255, 256, 257, 258], [95, 259, 2, 1, 260, 261, 262, 53, 263, 1, 96, 264, 15, 16, 97, 12, 43, 98, 265, 266, 2, 99, 267, 268, 269, 100, 2, 270, 271, 72, 16, 15, 272, 273, 29, 100, 75, 28, 101, 274, 102, 101, 1, 79, 17, 275, 276, 277, 2, 278, 279, 98, 280, 17, 19, 281, 282, 2, 283, 284, 42, 99, 1, 285, 286, 7, 287, 288, 7, 289, 38, 80, 93, 290, 291, 292, 293, 294, 295, 296, 297, 32, 6, 6, 298, 299, 34, 6, 12, 300, 17, 30, 38, 92], [9, 10, 11, 301, 103, 104, 302, 56, 105, 303, 104, 304, 87, 31, 305, 1, 306, 2, 307, 85, 308, 309, 310, 311, 36, 3, 96, 312, 12, 106, 44, 313, 314, 44, 315, 107, 2, 316, 317, 318, 319, 108, 18, 320, 321, 2, 107, 33, 19, 322, 97, 323, 324, 94, 12, 43, 43, 35, 40, 51, 42, 19, 325, 326, 327, 328, 329, 20, 95, 330, 331, 109, 332, 8, 4, 333, 45, 334, 335, 110, 336, 111, 1, 337, 338, 112, 1, 339, 340, 341, 112, 1, 113, 342, 21, 343, 344, 48, 345, 346, 3, 86, 20, 347, 37, 110, 348, 349, 29, 350, 351, 352, 70, 353, 114, 5, 354, 46, 89, 355, 356, 82, 357, 358, 359, 45, 360, 1, 361, 115, 362, 103, 45, 363, 91, 114, 5, 364, 46, 111, 365, 1, 366, 367, 109, 116, 117, 368, 116, 117, 369, 118, 370, 4, 78, 1, 26, 7, 63, 371, 3, 24, 372, 105, 118, 373, 374, 1, 375, 119, 376, 377, 18, 83, 39, 76, 4, 378, 106, 44, 379, 119, 380, 381, 382, 39, 383, 384, 385, 386, 387, 388, 389, 108, 20, 390, 391, 392, 115, 393, 3, 394, 14, 395, 396, 397, 46, 398, 399, 400, 40, 401, 402, 84, 41, 403, 404, 102, 20, 405, 8, 406], [113, 407, 408]]\n",
      "0.045206308364868164\n"
     ]
    }
   ],
   "source": [
    "# Text to sequence\n",
    "seq_tokenizer = Tokenizer(num_words = 1000)\n",
    "seq_tokenizer.fit_on_texts(processed_review)\n",
    "\n",
    "seq = seq_tokenizer.texts_to_sequences(processed_review)\n",
    "print(seq)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Notes\n",
    "\n",
    "Keras tutorial using functional neural networks not sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "x = [1,2,3,4,5]\n",
    "y = [4,5,6,7,8]\n",
    "\n",
    "# z = [i for i in x if i not in y]\n",
    "# z.extend([i for i in y])\n",
    "# print(z)\n",
    "\n",
    "z = list(set(x) | set(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
